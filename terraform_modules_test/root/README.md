# Module Terraform : Modern Data Stack - Pipeline Faker vers ADLS

## Architecture

Ce module Terraform dÃ©ploie un **Modern Data Stack** complet avec pipeline d'ingestion **Faker â†’ ADLS** basÃ© sur la logique validÃ©e du test WSL.

### **Infrastructure Azure**
- **Resource Group** : `ModernDataStack`
- **Storage Account** : `pimdsdatalake` (ADLS Gen2)
- **Containers** : `foldercsv`, `folderparquet`, `rootmoduletest`
- **Data Factory** : `pimdsdatafactory` avec pipeline CSV â†’ Parquet

### **Pipeline d'Ingestion Airbyte OSS**
- **Source Faker** : GÃ©nÃ©ration de 1000 enregistrements de donnÃ©es de test (users, products, purchases)
- **Destination Azure** : Export vers ADLS Gen2 en format CSV
- **Connexion** : Pipeline automatisÃ© Faker â†’ ADLS avec namespace "production_data"
- **ConfigurabilitÃ©** : Support GCS optionnel pour compatibilitÃ©

## PrÃ©requis

### **1. Airbyte OSS Local**
```bash
# Option 1: Via Git Clone
git clone https://github.com/airbytehq/airbyte.git
cd airbyte
./run-ab-platform.sh

# Option 2: Via Docker Compose (dans ce projet)
docker-compose up -d
```
Airbyte sera accessible sur http://localhost:8000 (airbyte/password)

### **2. Azure CLI**
```bash
# Installation (Windows)
winget install Microsoft.AzureCLI

# Connexion
az login
```

### **3. Terraform**
- Terraform >= 1.1.0
- Provider azurerm ~> 3.0.2
- Provider airbyte ~> 0.6.0

## Utilisation

### **DÃ©ploiement rapide**

#### **Windows PowerShell**
```powershell
cd terraform_modules_test/root
.\deploy.ps1
```

#### **Linux/WSL/Bash**
```bash
cd terraform_modules_test/root
chmod +x deploy.sh
./deploy.sh
```

### **DÃ©ploiement avec GCS**
```bash
# 1. Configurer les variables GCS
export GCS_BUCKET_NAME="votre-bucket-gcs"
export GCS_SERVICE_ACCOUNT_KEY='{"type":"service_account",...}'

# 2. DÃ©ployer
./deploy.sh
```

### **DÃ©ploiement manuel**
```bash
terraform init
terraform plan
terraform apply
```

## Configuration GCS (Optionnel)

### **1. CrÃ©er un Service Account GCS**
```bash
# CrÃ©er le service account
gcloud iam service-accounts create airbyte-reader \
    --description="Airbyte GCS Reader" \
    --display-name="Airbyte GCS Reader"

# Donner les permissions
gcloud projects add-iam-policy-binding YOUR_PROJECT_ID \
    --member="serviceAccount:airbyte-reader@YOUR_PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/storage.objectViewer"

# CrÃ©er la clÃ©
gcloud iam service-accounts keys create ~/gcs-key.json \
    --iam-account=airbyte-reader@YOUR_PROJECT_ID.iam.gserviceaccount.com
```

### **2. Configurer les variables**
```bash
export GCS_BUCKET_NAME="votre-bucket-csv"
export GCS_SERVICE_ACCOUNT_KEY=$(cat ~/gcs-key.json | tr -d '\n')
```

## Flux de donnÃ©es

```
Source Faker â†’ Airbyte â†’ Azure Blob (CSV) â†’ Data Factory â†’ Azure Blob (Parquet)
     â†“
Source GCS â†’ Airbyte â†’ Azure Blob (Parquet)
```

## VÃ©rification

### **1. Airbyte UI**
- AccÃ¨s : http://localhost:8000
- Credentials : `airbyte` / `password`
- VÃ©rifiez les sources, destinations et connexions

### **2. Azure Portal**
- Resource Group : `ModernDataStack`
- Storage Account : `pimdsdatalake`
- Containers : VÃ©rifiez les fichiers CSV et Parquet

### **3. Logs Terraform**
```bash
terraform output airbyte_faker_source_id
terraform output airbyte_azure_destination_id
```

## ğŸ› ï¸ Structure des modules

```
root/
â”œâ”€â”€ main.tf                    # Configuration principale
â”œâ”€â”€ deploy.sh                  # Script de dÃ©ploiement
â”œâ”€â”€ .env.example              # Configuration d'exemple
â””â”€â”€ modules/
    â”œâ”€â”€ order-test/           # Module stockage Azure existant
    â”‚   â””â”€â”€ submodules/azure-datalake/
    â””â”€â”€ airbyte-ingestion/    # Module Airbyte nouveau
        â”œâ”€â”€ main.tf
        â”œâ”€â”€ variables.tf
        â”œâ”€â”€ outputs.tf
        â””â”€â”€ submodules/
            â”œâ”€â”€ airbyte-sources/
            â””â”€â”€ airbyte-connections/
```