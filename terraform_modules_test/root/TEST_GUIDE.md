# ğŸ§ª Guide de Test : Faker â†’ ADLS avec Airbyte

## ğŸš€ DÃ©marrage rapide

### **Ã‰tape 1 : DÃ©marrer Airbyte OSS**
```bash
# Cloner et dÃ©marrer Airbyte (si pas dÃ©jÃ  fait)
git clone https://github.com/airbytehq/airbyte.git
cd airbyte
./run-ab-platform.sh    # Linux/Mac
# OU
.\run-ab-platform.bat   # Windows
```

Attendez que Airbyte soit accessible sur http://localhost:8000

### **Ã‰tape 2 : ExÃ©cuter le test**

#### **Option A : Script automatisÃ© (Windows)**
```powershell
cd terraform_modules_test/root
.\test_faker.ps1
```

#### **Option B : Script automatisÃ© (Linux/Mac)**
```bash
cd terraform_modules_test/root
chmod +x test_faker.sh
./test_faker.sh
```

#### **Option C : Manuel**
```bash
# Connexion Azure
az login

# Terraform
terraform init
terraform apply -target=module.order-test -target=airbyte_source_faker.test_faker -target=airbyte_destination_azure_blob_storage.test_adls -target=airbyte_connection.faker_to_adls_test
```

## ğŸ¯ Ce qui sera crÃ©Ã©

### **Infrastructure Azure**
- âœ… Resource Group : `ModernDataStack`
- âœ… Storage Account : `pimdsdatalake` (ADLS Gen2)
- âœ… Container : `foldercsv`

### **Configuration Airbyte**
- âœ… Source Faker : GÃ©nÃ¨re 1000 records (users, products, purchases)
- âœ… Destination ADLS : Export vers votre storage account
- âœ… Connexion : Pipeline Faker â†’ ADLS (mode manuel)

## ğŸ”„ Tester l'ingestion

### **1. Interface Airbyte**
1. Ouvrir http://localhost:8000
2. Login : `airbyte` / `password`
3. Aller dans **Connections** â†’ **Faker to ADLS Test**
4. Cliquer sur **"Sync now"**

### **2. VÃ©rifier les donnÃ©es**
1. **Azure Portal** : portal.azure.com
2. **Resource Group** : ModernDataStack
3. **Storage Account** : pimdsdatalake
4. **Container** : foldercsv
5. **Fichiers** : Vous devriez voir des fichiers CSV crÃ©Ã©s

### **3. Surveiller le progrÃ¨s**
- Les logs sont visibles dans l'UI Airbyte
- La premiÃ¨re sync prend gÃ©nÃ©ralement 1-3 minutes

## ğŸ“Š Structure des donnÃ©es gÃ©nÃ©rÃ©es

### **Streams Faker crÃ©Ã©s :**
- **users** : Utilisateurs fictifs avec id, nom, email, etc.
- **products** : Produits fictifs avec id, nom, prix, etc.
- **purchases** : Achats fictifs reliant users et products

### **Format de sortie :**
```
foldercsv/
â”œâ”€â”€ faker_test/
â”‚   â”œâ”€â”€ users/
â”‚   â”‚   â””â”€â”€ users_data.csv
â”‚   â”œâ”€â”€ products/
â”‚   â”‚   â””â”€â”€ products_data.csv
â”‚   â””â”€â”€ purchases/
â”‚       â””â”€â”€ purchases_data.csv
```

## ğŸ› ï¸ DÃ©pannage

### **âŒ Airbyte non accessible**
```bash
# VÃ©rifier le statut
docker ps | grep airbyte

# RedÃ©marrer si nÃ©cessaire
cd airbyte
docker-compose down
./run-ab-platform.sh
```

### **âŒ Erreur Azure connection**
```bash
# Re-login Azure
az logout
az login

# VÃ©rifier les permissions
az account list --output table
```

### **âŒ Sync Ã©choue dans Airbyte**
1. VÃ©rifier les credentials de destination dans l'UI
2. Tester la connection manuellement
3. Consulter les logs dÃ©taillÃ©s

## ğŸ‰ RÃ©sultat attendu

Si tout fonctionne :
- âœ… Infrastructure Azure dÃ©ployÃ©e
- âœ… Source et destination Airbyte configurÃ©es
- âœ… Sync manuel rÃ©ussi
- âœ… Fichiers CSV dans le container ADLS

## ğŸ”„ Nettoyage (optionnel)

```bash
# Supprimer les ressources de test
terraform destroy -target=airbyte_connection.faker_to_adls_test -target=airbyte_destination_azure_blob_storage.test_adls -target=airbyte_source_faker.test_faker

# Supprimer l'infrastructure Azure (attention !)
terraform destroy
```
