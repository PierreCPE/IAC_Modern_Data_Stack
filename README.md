# Modern Data Stack - Infrastructure as Code

[![Azure](https://img.shields.io/badge/Azure-0078D4?style=flat&logo=microsoft-azure&logoColor=white)](https://azure.microsoft.com/)
[![Terraform](https://img.shields.io/badge/Terraform-623CE4?style=flat&logo=terraform&logoColor=white)](https://terraform.io/)
[![Airbyte](https://img.shields.io/badge/Airbyte-615EFF?style=flat&logo=airbyte&logoColor=white)](https://airbyte.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://docker.com/)

> **Infrastructure as Code pour un Modern Data Stack complet** intÃ©grant **Azure Data Lake Storage (ADLS)**, **Airbyte OSS**, **Azure Data Factory**, et **Snowflake/dbt** avec orchestration Terraform.

## ğŸ—ï¸ Architecture Globale

![Architecture Modern Data Stack](./docs/images/architecture.png)

*Figure 1: Vue d'ensemble du Modern Data Stack avec flux de donnÃ©es*

## ğŸ¯ FonctionnalitÃ©s

### âœ¨ **Infrastructure Azure**
- **Resource Group** : `ModernDataStack`
- **Storage Account ADLS Gen2** : `pimdsdatalake` 
- **Containers** : `foldercsv`, `folderparquet`, `rootmoduletest`, ou le container fournit par Keyrus.
- **Azure Data Factory** : Pipeline de conversion CSV â†’ Parquet


### ğŸ”„ **Pipeline d'Ingestion**
- **Airbyte OSS** : Ingestion temps rÃ©el via Terraform ou API REST
- **Sources** : Faker (test), ADLS Gen 2 Keyrus.
- **Destinations** : Azure Data Lake Storage Gen2
- **Formats** : CSV, Parquet avec compression optimisÃ©e

### ğŸ› ï¸ **Outils de Transformation**
- **dbt** : Transformation de donnÃ©es SQL-first
- **Azure Data Factory** : Orchestration et monitoring
- **Support multi-environnements** : dev, staging, production

### ğŸ“Š **Visualisation**
- **Streamlit** : Dashboards et analyses
- **IntÃ©gration native** avec Snowflake - en construction

## ğŸš€ Quick Start

### 1. **PrÃ©requis**

```bash
# Azure CLI
az login

# Terraform
terraform --version  # >= 1.1.0

# Docker pour Airbyte
docker --version
docker-compose --version
```

### 2. **DÃ©marrage Airbyte OSS**

```bash
# Option 1: Docker Compose (recommandÃ©)
cd airbyte/
docker-compose up -d

# Option 2: Installation classique
git clone https://github.com/airbytehq/airbyte.git
cd airbyte
./run-ab-platform.sh
```

**AccÃ¨s** : http://localhost:8000 (airbyte/password)

### 3. **DÃ©ploiement Infrastructure**

#### **Approche Test/Validation**
```bash
cd terraform_modules_test/wsl_test/
chmod +x test_wsl.sh
./test_wsl.sh
```

#### **DÃ©ploiement Production**
```bash
cd terraform_modules_test/root/

# Linux/WSL/Bash
chmod +x deploy.sh
./deploy.sh
```

### 4. **VÃ©rification**

```bash
# Azure Portal
# â†’ Resource Groups â†’ ModernDataStack â†’ pimdsdatalake

# Airbyte UI
# â†’ http://localhost:8000 â†’ Connections
```

## ğŸ“ Structure du Projet
Tout ce qu'il y a dans sandbox se retrouve sur diverse branches du projet.


```
IAC_Modern_Data_Stack/
â”œâ”€â”€ README.md                          # ğŸ“– Ce fichier
â”œâ”€â”€ docker-compose.yml                 # ğŸ³ Airbyte + services
â”œâ”€â”€ .gitignore                         # Exclusions Git
â”‚
â”‚
â””â”€â”€ sandbox/                               # Dossier pour les pocs.
    â”œâ”€â”€ airbyte/                           # ğŸ”„ Configuration Airbyte
    â”‚   â””â”€â”€ test_airbyte                   # Tests de connectivitÃ©
    â”‚
    â”œâ”€â”€ datalake/                          # ğŸ’¾ Configuration ADLS
    â”‚   â”œâ”€â”€ azureDeployment.tf             # DÃ©ploiement Azure direct
    â”‚   â””â”€â”€ usageGuide.txt                 # Guide d'utilisation
    â”‚
    â”œâ”€â”€ dbt/                               # ğŸ› ï¸ Transformations dbt
    â”‚   â””â”€â”€ test_dbt                       # Tests et modÃ¨les
    â”‚
    â”œâ”€â”€ metabase/                          # ğŸ“Š Configuration Metabase
    â”‚   â””â”€â”€ test_metabase                  # Dashboards de test
    â”‚
    â”œâ”€â”€ terraform/                        # ğŸ—ï¸ Modules Terraform (legacy)
â”‚
â””â”€â”€ terraform_modules_test/           # ğŸ§ª Modules Terraform principaux
    â”œâ”€â”€ wsl_test/                      # âœ… Environnement de test validÃ©
    â”‚   â”œâ”€â”€ main.tf                    # Pipeline Faker â†’ ADLS
    â”‚   â”œâ”€â”€ test_wsl.sh               # Script de test automatisÃ©
    â”‚   â”œâ”€â”€ run_from_windows.ps1      # Lancement depuis Windows
    â”‚   â””â”€â”€ WSL_TROUBLESHOOTING.md     # Guide de dÃ©pannage
    â”‚
    â””â”€â”€ root/                          # ğŸ­ Environnement de production
        â”œâ”€â”€ main.tf                    # Configuration principale
        â”œâ”€â”€ deploy.sh / deploy.ps1     # Scripts de dÃ©ploiement
        â”œâ”€â”€ test_pipeline.sh           # Tests de validation
        â”œâ”€â”€ configure_airbyte.sh       # Configuration API REST Airbyte
        â”‚
        â””â”€â”€ modules/                   # ğŸ“¦ Modules Terraform
            â”œâ”€â”€ order-test/            # Infrastructure Azure
            â”‚   â””â”€â”€ submodules/azure-datalake/
            â””â”€â”€ airbyte-ingestion/     # Pipeline Airbyte
                â”œâ”€â”€ main.tf
                â”œâ”€â”€ variables.tf
                â”œâ”€â”€ outputs.tf
                â””â”€â”€ submodules/
                    â”œâ”€â”€ airbyte-sources/
                    â””â”€â”€ airbyte-connections/
```

## ğŸ¯ Cas d'Usage

### 1. **Test et Validation** 
```bash
# Environnement isolÃ© pour tester les pipelines
cd terraform_modules_test/wsl_test/
./test_wsl.sh

# âœ… Pipeline validÃ© : Faker (1000 records) â†’ ADLS (CSV)
```

### 2. **Ingestion GCS â†’ Azure**
```bash
# Configuration GCS
export GCS_BUCKET_NAME="your-bucket"
export GCS_SERVICE_ACCOUNT_KEY='{"type":"service_account",...}'

# DÃ©ploiement avec source GCS
cd terraform_modules_test/root/
./deploy.sh
```


## ğŸ”§ Configuration AvancÃ©e

### **Variables d'Environnement**

```bash
# Airbyte
export AIRBYTE_SERVER_URL="http://localhost:8000"
export WORKSPACE_ID="5ae6b09b-fdec-41af-aed7-204436cc6af6"

# Azure
export AZURE_SUBSCRIPTION_ID="your-subscription-id"
export AZURE_RESOURCE_GROUP="ModernDataStack"

# GCS (optionnel)
export GCS_BUCKET_NAME="your-bucket"
export GCS_SERVICE_ACCOUNT_KEY="your-service-account-json"

# Terraform
export TF_LOG="INFO"
export TF_LOG_PATH="./terraform.log"
```

### **Personnalisation des Modules**

```hcl
# terraform_modules_test/root/main.tf
module "airbyte-ingestion" {
  source = "./modules/airbyte-ingestion"
  
  # Configuration personnalisÃ©e
  csv_container_name     = "your-csv-folder"
  parquet_container_name = "your-parquet-folder"
  
  # Sources multiples
  gcs_bucket_name = var.gcs_bucket_name
  faker_records_count = 5000  # Plus de donnÃ©es
}
```

## ğŸ§ª Tests et Validation

### **Tests AutomatisÃ©s**
```bash
# Test complet de bout en bout
cd terraform_modules_test/wsl_test/
./test_wsl.sh

# Test de l'infrastructure Azure seule
cd terraform_modules_test/root/
terraform plan -target="module.order-test"

# Test du pipeline Airbyte
./test_pipeline.sh
```

### **Monitoring**
```bash
# Logs Terraform
tail -f terraform.log

# Statut Airbyte
curl http://localhost:8000/api/v1/health

# VÃ©rification Azure
az storage blob list --container-name foldercsv --account-name pimdsdatalake
```

## ğŸš¨ Troubleshooting

### **ProblÃ¨mes Courants**

| ProblÃ¨me | Solution |
|----------|----------|
| Airbyte 405 Error | VÃ©rifier version provider + credentials |
| Azure 401 Unauthorized | `az login` + vÃ©rifier subscription |
| WSL Networking Issues | Voir `WSL_TROUBLESHOOTING.md` |

### **Debug Mode**
```bash
# Terraform verbose
export TF_LOG=DEBUG

# Test de connectivitÃ©
curl -v http://localhost:8000/api/v1/health

# VÃ©rification Azure CLI
az account show
```

## ğŸŒŸ Roadmap

### **Version Actuelle (v1.0)**
- âœ… Infrastructure Azure (ADLS, Data Factory)
- âœ… Airbyte OSS (Faker, GCS sources)
- âœ… Pipeline Ingestion â†’ ADLS Gen2 â†’ CSV â†’ Parquet


### **Prochaines Versions**
- ğŸ”„ **v1.1** : IntÃ©gration Snowflake/dbt complÃ¨te dans le pipeline (pour l'instant isolÃ© en fin de chaine)
- ğŸ“Š **v1.2** : Rattachage du UseCase Taxi (pour l'instant juste mise des fichiers Taxi dans ADLS Gen2, mais dbt+streamlit fait pour taxis)
- ğŸ”’ **v1.3** : SÃ©curitÃ© et RBAC
- â˜ï¸ **v1.4** : Multi-cloud (AWS, GCP)
- ğŸ¤– **v1.5** : CI/CD Pipeline

## ğŸ¤ Contribution

### **Development Workflow**
```bash
# 1. CrÃ©er une branche
git checkout -b feature/nouvelle-fonctionnalite

# 2. Tester en local
cd terraform_modules_test/wsl_test/
./test_wsl.sh

# 3. Valider en production
cd terraform_modules_test/root/
terraform plan

# 4. Submit PR
```

### **Standards**
- **Terraform** : Format avec `terraform fmt`
- **Documentation** : Mise Ã  jour des README
- **SÃ©curitÃ©** : Pas de credentials en dur


## ğŸ“„ License

Ce projet est dÃ©veloppÃ© dans le cadre d'un stage chez **Keyrus** pour l'industrialisation d'un Modern Data Stack avec Infrastructure as Code.

**Auteurs** : Pierre Gosson, Amin Akkouche, Valentin Pisano-Banchet

**Organisation** : Keyrus  
**PÃ©riode** : 2025  

---